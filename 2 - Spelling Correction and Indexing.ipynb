{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "static-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-translator",
   "metadata": {},
   "source": [
    "# Edit Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-restaurant",
   "metadata": {},
   "source": [
    "#### 1. Buatlah sebuah fungsi “edit_distance”. Fungsi tersebut memiliki dua buah parameter string yaitu string_1 dan string_2. Fungsi ini dapat menghitung Levenshtein Distance antara string_1 dengan string_2. Lebih jelasnya lagi, fungsitersebut akan mengembalikan nilai terkecil yang dibutuhkan untuk mentransformasi string_1 menjadi string_2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "least-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(string_1, string_2):\n",
    "    # menambahkan nilai awal selain indexnya dengan 0 \n",
    "    matrix = np.zeros((len(string_1) + 1, len(string_2) + 1))\n",
    "\n",
    "    for x in range(len(string_1) + 1):\n",
    "        matrix[x][0] = x\n",
    "\n",
    "    for y in range(len(string_2) + 1):\n",
    "        matrix[0][y] = y\n",
    "        \n",
    "    # mencari bobot tiap huruf berdasarkan algoritma levenshtein distance\n",
    "    for i in range (len(string_1) + 1):\n",
    "        for j in range (len(string_2) + 1):\n",
    "            if i == 0 or j == 0:\n",
    "                matrix[i][j] = max(i, j)\n",
    "            else:\n",
    "                a = matrix[i - 1][j - 1]\n",
    "                b = matrix[i][j - 1] + 1\n",
    "                c = matrix[i - 1][j] + 1\n",
    "       \n",
    "                if string_1[i - 1] != string_2[j - 1]:\n",
    "                    a += 1\n",
    "       \n",
    "                matrix[i][j] = min(a, b, c)\n",
    "    return matrix[len(string_1)][len(string_2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-simpson",
   "metadata": {},
   "source": [
    "#### 2. Menggunakan fungsi yang telah dibuat pada soal sebelumnya, carilah nilai edit_distance dari pasangan kata berikut ini:\n",
    "<p>phasmophobia - puafnilhotik </p>\n",
    "<p>genetik - ganteng</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "italian-jungle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n",
      "5.0\n"
     ]
    }
   ],
   "source": [
    "print(edit_distance('phasmophobia','puafnilhotik'))\n",
    "print(edit_distance('genetik','ganteng'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-burst",
   "metadata": {},
   "source": [
    "#### 4. Menggunakan matriks M yang telah dibuat pada soal sebelumnya, carilah nilai edit_distance dari pasangan kata berikut ini:\n",
    "<p>a. phasmophobia - puafnilhotik</p>\n",
    "<p>b. genetik - ganteng</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "olive-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "total  = []\n",
    "def keyboard_distance(max_overall,distance):\n",
    "    total.append((max_overall-distance)/max_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "elect-grain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit distance phasmophobia - puafnilhotik adalah : 10.461538461538463\n"
     ]
    }
   ],
   "source": [
    "#a. phasmophobia - puafnilhotik\n",
    "distance = [0,1,0,2,1,1,1,0,0,2,0,7]\n",
    "for i in distance:\n",
    "    keyboard_distance(9.75,i)\n",
    "edit_distance = 0\n",
    "for i in total:\n",
    "    edit_distance += i\n",
    "print(\"Edit distance phasmophobia - puafnilhotik adalah : \" + str(edit_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pending-tattoo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit distance genetik - ganteng adalah : 5.871794871794871\n"
     ]
    }
   ],
   "source": [
    "#b. genetik - ganteng\n",
    "total  = []\n",
    "distance = [0,2,0,2,2,2,3]\n",
    "for i in distance:\n",
    "    keyboard_distance(9.75,i)\n",
    "edit_distance = 0\n",
    "for i in total:\n",
    "    edit_distance += i\n",
    "print(\"Edit distance genetik - ganteng adalah : \" + str(edit_distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-variation",
   "metadata": {},
   "source": [
    "#### 5. Bandingkan hasil yang kamu temui pada nomor A2 dan A4. Apa yang dapat kamu simpulkan terkait kedua metode edit distance ini? Selain itu, apakah kedua algoritma edit distance ini sudah sempurna? Jelaskan analisis singkat kamu minimal dalam 3 kalimat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "transparent-disabled",
   "metadata": {},
   "source": [
    ">Dari perbandingan hasil diatas terlihat bahwa keyboard distance memiliki hasil  edit distance yang lebih besar dibandingkan menggunakan Levenshtein Distance. Hal itu dikarenakan lavenshtein distance menghitung jumlah minimal perubahan antara satu string ke string lain sedangkan keyboard distance hanya melihat jumlah jarak antar karakter di keyboard yang tidak sama. Itu membuat menggunakan levenshtein distance lebih bagus dibandingkan keyboard distance untuk candidate generation. Hal itu karena kesalahan kata tidak hanya kesalahan penulisan(typo pada keyboard) namun bisa saja pengguna memang tidak tahu ejaan yang benar dari kata yang sudah diketik. Namun, menurut saya kedua algoritma edit distance ini tetap masih belum sempurna karena tidak akan menjamin akan menghasilkan keakuratan 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-guatemala",
   "metadata": {},
   "source": [
    "#  N-Gram Language Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-gates",
   "metadata": {},
   "source": [
    "<p>Perhatikan empat kalimat berikut</p>\n",
    "<p>K1 : orang itu menjadi kepala rumah sakit di desa</p>\n",
    "<p>K2 : kepala orang itu sedang sakit di rumah sakit</p>\n",
    "<p>K3 : kepala rumah sakit itu memakan kelapa bersama warga desa</p>\n",
    "<p>K4 : orang sakit itu memakan kelapa bersama kepala rumah sakit</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-latvia",
   "metadata": {},
   "source": [
    "#### 1. Jika diberikan threshold sebesar 10^-12 dengan menggunakan language model bigram dan trigram, Manakah di antara kalimat berikut ini yang memiliki kecenderungan pada spelling error? Tunjukkan peluang dari setiap kalimat berikut dan tentukan kalimat yang mengandung spelling error!\n",
    "<p>a. warga desa sedang sakit kelapa di rumah sakit</p>\n",
    "<p>b. orang itu sedang berada di rumah sakit</p>\n",
    "<p>c. rumah sakit di desa itu tempat warga memakan kepala</p>\n",
    "<p>d. orang sakit sedang memakan kelapa bersama warga desa<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "engaged-allowance",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sentence = \"orang itu menjadi kepala rumah sakit di desa kepala orang itu sedang sakit di rumah sakit kepala rumah sakit itu memakan kelapa bersama warga desa  orang sakit itu memakan kelapa bersama kepala rumah sakit\"\n",
    "result_word = []\n",
    "sentence = all_sentence.split()\n",
    "for word in sentence:\n",
    "    result_word.append(word)\n",
    "\n",
    "word_df = pd.DataFrame(result_word, columns=[\"word\"])\n",
    "word_df_count = word_df[\"word\"].value_counts().to_frame(name=\"count\")\n",
    "\n",
    "list_pword =[]\n",
    "for i in word_df_count['count'] :\n",
    "    p = i /len(result_word)\n",
    "    list_pword.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "collective-cancer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>P(w)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sakit</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rumah</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>itu</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kepala</td>\n",
       "      <td>0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orang</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bersama</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kelapa</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>di</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>desa</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>memakan</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>menjadi</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sedang</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>warga</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word      P(w)\n",
       "0     sakit  0.176471\n",
       "1     rumah  0.117647\n",
       "2       itu  0.117647\n",
       "3    kepala  0.117647\n",
       "4     orang  0.088235\n",
       "5   bersama  0.058824\n",
       "6    kelapa  0.058824\n",
       "7        di  0.058824\n",
       "8      desa  0.058824\n",
       "9   memakan  0.058824\n",
       "10  menjadi  0.029412\n",
       "11   sedang  0.029412\n",
       "12    warga  0.029412"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mendapatkan probabilitas setiap kata\n",
    "word = ['sakit','rumah','itu','kepala','orang','bersama','kelapa','di','desa','memakan','menjadi','sedang','warga']        \n",
    "df = pd.DataFrame(word, columns=[\"word\"])\n",
    "df['P(w)'] =  pd.Series(list_pword)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-saint",
   "metadata": {},
   "source": [
    "##### Bagian A \n",
    "##### a. warga desa sedang sakit kelapa di rumah sakit\n",
    "\n",
    "<p>1. Bigram</p>\n",
    "<p>P(a) = </p>\n",
    "<p>p(warga) * P(desa | warga) * P(sedang | desa) * P(sakit | sedang) * P(kelapa | sakit) * p(di | kelapa) * P(rumah | di ) * P(sakit | rumah)\n",
    "\n",
    "<p>2. Trigram</p>\n",
    "<p>P(a) = </p>\n",
    "<p>p(warga | *, *) * P(desa | *, warga) * P(sedang | warga, desa) * P (sakit | desa, sedang) * </p>\n",
    "<p>P(kelapa | sedang, sakit) * P(di | sakit, kelapa) * P(rumah | kelapa, di) * P(sakit | di, rumah) </p>\n",
    "\n",
    "#### P(warga | *, *) ama P(desa | *, warga) maksudnya peluang kata warga didepan kalimat sama peluang desa apabila sebelumnya kata warga yg didepan kalimat ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "drawn-withdrawal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a bigram : 0.014706\n",
      "a trigram : 0.000865065744\n"
     ]
    }
   ],
   "source": [
    "#Bigram\n",
    "total_a_bigram = 0.029412 * 1 * 1 * 1 * 0.5 * 1 * 1 * 1\n",
    "print(\"a bigram : \" + str(total_a_bigram))\n",
    "\n",
    "#Trigram\n",
    "total_a_trigram = 0.029412 * 0.029412  * 1 *  1 * 1 * 1 * 1 * 1\n",
    "print(\"a trigram : \" + str(total_a_trigram))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-reservoir",
   "metadata": {},
   "source": [
    "##### Bagian B\n",
    "##### b. orang itu sedang berada di rumah sakit\n",
    "\n",
    "<p>1. Bigram</p>\n",
    "<p>P(b) = </p>\n",
    "<p>p(orang) * P(itu | orang) * P(sedang | itu) * P(berada | sedang) * P(di | berada) * p(rumah | di) * P(sakit| rumah ) \n",
    "\n",
    "<p>2. Trigram</p>\n",
    "<p>P(b) = </p>\n",
    "<p>p(orang | *, *) * P(itu | *, orang) * P(sedang | orang, itu) * P (berada | itu, sedang) * </p>\n",
    "<p>P(di | sedang, berada) * P(rumah | berada, di) * P(sakit | di, rumah) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "minor-journal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b bigram : 6.17892156862745e-06\n",
      "b trigram : 7.269319492502882e-07\n"
     ]
    }
   ],
   "source": [
    "#Bigram\n",
    "total_b_bigram = 0.088235 * (1/3) * (1) * (1/35) * (1/34) * 1 * (1/4)\n",
    "print(\"b bigram : \" + str(total_b_bigram))\n",
    "\n",
    "#Trigram\n",
    "total_b_trigram = 0.088235 * (1/3)  * 1 *  (1/35) * (1/34)  * (1/34) * 1 \n",
    "print(\"b trigram : \" + str(total_b_trigram))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-original",
   "metadata": {},
   "source": [
    "##### Bagian C \n",
    "##### C. rumah sakit di desa itu tempat warga memakan kepala\n",
    "\n",
    "<p>1. Bigram</p>\n",
    "<p>P(a) = </p>\n",
    "<p>p(rumah) * P(sakit | rumah) * P(di | sakit) * P(desa | di) * P(itu | desa) * p(tempat | itu) * P(warga | tempat ) * P(memakan | warga) * P(kepala | memakan)\n",
    "\n",
    "<p>2. Trigram</p>\n",
    "<p>P(a) = </p>\n",
    "<p>p(rumah | *, *) * P(sakit | *, rumah) * P(di | rumah, sakit) * P (desa | sakit, di) * </p>\n",
    "<p>P(itu | di, desa) * P(tempat | desa, itu) * P(warga | itu, tempat) * P(memakan | tempat, warga)*  P(kepala | warga, memakan)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "personal-criminal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c bigram : 1.2721345155709343e-05\n",
      "c trigram : 6.473308139481652e-10\n"
     ]
    }
   ],
   "source": [
    "#Bigram\n",
    "total_c_bigram = 0.117647 * (1/4) * (1) * (1) * (1/2) * (1/34) * (1/34)*1*1\n",
    "print(\"c bigram : \" + str(total_c_bigram))\n",
    "\n",
    "#Trigram\n",
    "total_c_trigram = 0.117647 * (1/4)  * 1 *  (1) * (1/34)  * (1/34) *(1/34)* (1/34)*(1/34)\n",
    "print(\"c trigram : \" + str(total_c_trigram))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-biography",
   "metadata": {},
   "source": [
    "##### Bagian D\n",
    "##### D. orang sakit sedang memakan kelapa bersama warga desa\n",
    "\n",
    "<p>1. Bigram</p>\n",
    "<p>P(a) = </p>\n",
    "<p>p(orang) * P(sakit | orang) * P(sedang | sakit) * P(memakan | sedang) * P(kelapa | memakan) * p(bersama | kelapa) * P(warga | bersama ) * P(desa | warga)\n",
    "\n",
    "<p>2. Trigram</p>\n",
    "<p>P(a) = </p>\n",
    "<p>p(orang | *, *) * P(sakit | *, orang) * P(sedang | orang, sakit) * P (memakan | sakit, sedang) * </p>\n",
    "<p>P(kela[a | sedang, memakan) * P(bersama | memakan, kelapa) * P(warga | kelapa, bersama) * P(desa | bersama, warga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "careful-approval",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d bigram : 3.816392733564013e-06\n",
      "d trigram : 2.2449369020964784e-07\n"
     ]
    }
   ],
   "source": [
    "#Bigram\n",
    "total_d_bigram = 0.088235* (1/5) * (1) * (1/34) * (1/2) * (1/2) * (1/34)*1*1\n",
    "print(\"d bigram : \" + str(total_d_bigram))\n",
    "\n",
    "#Trigram\n",
    "total_d_trigram = 0.088235 * (1/5)  * (1/34) *  (1/34) * (1/34)  * (1/2) *(1)*1\n",
    "print(\"d trigram : \" + str(total_d_trigram))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-daughter",
   "metadata": {},
   "source": [
    "> Dari hasil diatas terbukti bahwa yang paling mendekati spelling  error adalah bagian c yaitu  rumah sakit di desa itu tempat warga memakan kepala"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-graham",
   "metadata": {},
   "source": [
    "#### 2. Dalam kasus umum (tidak terbatas pada soal ini), menurut kamu, manakah yang lebih baik; language model unigram, bigram, atau trigram? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proud-shelf",
   "metadata": {},
   "source": [
    "1-gram (atau unigram) adalah urutan satu string. 2 gram (atau bigram) adalah rangkaian urutan dua string.  Dan 3-gram (atau trigram) adalah rangkaian urutan tiga string. Pada umumnya, semakin tinggi N, semakin baik atau akurat biasanya. Hal itu berarti trigram biasanya yang lebih baik . Tetapi hal tersebut mempunyai kelemahan karena dapat menyebabkan banyak overhead komputasi yang membutuhkan daya komputasi besar dalam hal RAM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-statistics",
   "metadata": {},
   "source": [
    "#### 3. Menurut kamu apakah N-gram language model yang standar sudah baik untuk diterapkan pada bahasa yang kaya secara morfologis, seperti Bahasa Indonesia? Apa saja masalah berkaitan dengan morfologis yang mungkin ditemukan pada kasus ini? Ceritakan strategi kamu dalam mengatasinya dikaitkan dengan pengetahuan yang telah didapatkan pada bagian Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-humanity",
   "metadata": {},
   "source": [
    "Morfologi adalah ilmu yang mempelajari seluk-beluk kata serta fungsi perubahan-perubahan kata baik dalam fungsi gramatik (arti kata berdasarkan konteks penggunaan) maupun fungsi semantik (arti kata berdasarkan makna leksikal/kamus).\n",
    "N-gram language model sendiri digunakan untuk memprediksi probabilitas dari urutan kata . N-gram language model mengambil potongan N-karakter yang diambilkan dari suatu string. Hal itu menyebabkan n-gram language model sendiri cukup menjadi standar yang baik untuk diterapkan pada bahasa secara morfologis dalam perubahan- perubahan kata. Namun, N-gram languange juga memiliki kelemahan seperti terbatasnya terhadap kata- kata yang tidak muncul sehingga adalah melakukan smoothing untuk\n",
    "menghindari agar probabilitynya tidak 0. Selain itu, n-diagram juga mempunyai kelemahan seperti kurang tidak bekerja dengan biak dalam  longer-distance context.Oleh karena itu, language models yang lain seperti semantic indexing bekerja lebih baik."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-glass",
   "metadata": {},
   "source": [
    "# Pemetaan Dokumen dan Teks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-graham",
   "metadata": {},
   "source": [
    "#### 1. Buatlah pemetaan seluruh kata yang sudah dalam bentuk kata dasar lowercase dan bukan termasuk dalam stopwords dengan jumlah kemunculan kata tersebut di setiap dokumen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dominican-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_a = \"Sivitas Akademika Universitas Indonesia menjalankan aktivitas perkuliahan secara daring yang diikuti oleh mahasiswa dari seluruh jenjang. Hal ini diakibatkan karena adanya pandemi COVID-19 di Indonesia selama satu setengah tahun belakang.\"\n",
    "document_b = \"Masyarakat memiliki respon berbeda dalam menyikapi pandemi COVID-19. Salah satu mahasiswa bernama Dipsy mengatakan kesulitan untuk belajar dengan maksimal karena sulit untuk berdiskusi dengan orang yang lebih pandai.\"\n",
    "document_c = \"Salah satu kunci untuk menghadapi musibah adalah dengan bersabar dan yakin semua musibah akan berlalu pada waktunya. Badai pasti berlalu, jadi harus tetap semangat.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "incorporated-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_a = document_a.lower()\n",
    "document_b = document_b.lower()\n",
    "document_c = document_c.lower()\n",
    "all_document = [document_a,document_b,document_c]\n",
    "\n",
    "cachedStopWords = stopwords.words(\"indonesian\")\n",
    "\n",
    "#menghilangkan tanda baca\n",
    "result_list=[] \n",
    "for i in all_document:\n",
    "    r = re.findall('[^.\\,\"]',i)\n",
    "    result = ''.join(r)\n",
    "    result_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interested-liver",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenisasi kata dan menghilangkan stopwords\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "final_word =[]\n",
    "for i in result_list:\n",
    "    sent_word = nltk.word_tokenize(i)\n",
    "    for word in sent_word:\n",
    "        if word not in cachedStopWords:\n",
    "             if word not in final_word:\n",
    "                    output = stemmer.stem(word)\n",
    "                    final_word.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "innovative-method",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sivitas', 'akademika', 'universitas', 'indonesia', 'aktivitas', 'daring', 'mahasiswa', 'jenjang', 'pandemi', 'covid-19']\n"
     ]
    }
   ],
   "source": [
    "result_dok_a = []\n",
    "list_dok_a = result_list[0].split() \n",
    "for word in list_dok_a:\n",
    "    if word in final_word:\n",
    "        if word not in result_dok_a:\n",
    "            result_dok_a.append(word)\n",
    "print(result_dok_a)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "linear-winner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['masyarakat', 'respon', 'pandemi', 'covid-19', 'salah', 'mahasiswa', 'dipsy', 'maksimal', 'sulit', 'orang', 'pandai']\n"
     ]
    }
   ],
   "source": [
    "result_dok_b = []\n",
    "list_dok_b = result_list[1].split() \n",
    "for word in list_dok_b:\n",
    "    if word in final_word:\n",
    "        if word not in result_dok_b:\n",
    "            result_dok_b.append(word)\n",
    "print(result_dok_b)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "offensive-double",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['salah', 'kunci', 'musibah', 'badai', 'semangat']\n"
     ]
    }
   ],
   "source": [
    "result_dok_c = []\n",
    "list_dok_c = result_list[2].split() \n",
    "for word in list_dok_c:\n",
    "    if word in final_word:\n",
    "        if word not in result_dok_c:\n",
    "            result_dok_c.append(word)\n",
    "print(result_dok_c)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "comprehensive-leave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>doc_A</th>\n",
       "      <th>doc_B</th>\n",
       "      <th>doc_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sivitas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>akademika</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>universitas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indonesia</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jalan</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>aktivitas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kuliah</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>daring</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ikut</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mahasiswa</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jenjang</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>akibat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pandemi</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>covid-19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>masyarakat</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>milik</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>respon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>beda</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sikap</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>salah</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>nama</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dipsy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sulit</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ajar</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>maksimal</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>diskus</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>orang</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>pandai</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>kunci</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>hadap</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>musibah</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sabar</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>badai</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>semangat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  doc_A  doc_B  doc_C\n",
       "0       sivitas      1      0      0\n",
       "1     akademika      1      0      0\n",
       "2   universitas      1      0      0\n",
       "3     indonesia      1      0      0\n",
       "4         jalan      1      0      0\n",
       "5     aktivitas      1      0      0\n",
       "6        kuliah      1      0      0\n",
       "7        daring      1      0      0\n",
       "8          ikut      1      0      0\n",
       "9     mahasiswa      1      1      0\n",
       "10      jenjang      1      0      0\n",
       "11       akibat      1      0      0\n",
       "12      pandemi      1      1      0\n",
       "13     covid-19      1      1      0\n",
       "14   masyarakat      0      1      0\n",
       "15        milik      0      1      0\n",
       "16       respon      0      1      0\n",
       "17         beda      0      1      0\n",
       "18        sikap      0      1      0\n",
       "19        salah      0      1      1\n",
       "20         nama      0      1      0\n",
       "21        dipsy      0      1      0\n",
       "22        sulit      0      1      0\n",
       "23         ajar      0      1      0\n",
       "24     maksimal      0      1      0\n",
       "25       diskus      0      1      0\n",
       "26        orang      0      1      0\n",
       "27       pandai      0      1      0\n",
       "28        kunci      0      1      0\n",
       "29        hadap      0      0      1\n",
       "30      musibah      0      0      1\n",
       "31        sabar      0      0      1\n",
       "32        badai      0      0      1\n",
       "33     semangat      0      0      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_df = pd.DataFrame(final_word, columns=[\"word\"])\n",
    "word_df['doc_A'] =  pd.Series([1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "word_df['doc_B'] =  pd.Series([0,0,0,0,0,0,0,0,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0])\n",
    "word_df['doc_C'] =  pd.Series([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1])\n",
    "word_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-principle",
   "metadata": {},
   "source": [
    "#### 2. Jika menjalankan masing-masing query berikut, dokumen manakah yang akan ditemukan?\n",
    "<p>a. akibat AND sulit\n",
    "<p>b. waktu OR santai\n",
    "<p>c. (masyarakat AND mahasiswa) OR sabar\n",
    "<p>d. (libur OR respon) OR (waktu AND jenjang)\n",
    "<p>e. (kunci OR musibah) AND NOT (aktivitas AND pandemi) OR maksimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-vaccine",
   "metadata": {},
   "source": [
    "##### Jawab:\n",
    "<p>a. Tidak akan menemukan dokumen apapun, karena dapat kita lihat dari hasil pemetaan seluruh kata tidak ada dokumen satupun yang memiliki kata akibat dan kata sulit</p>\n",
    "\n",
    "<p>b. Tidak akan menemukan dokumen apapun, karena dapat kita lihat dari hasil pemetaan seluruh kata tidak ada dokumen satupun yang memiliki kata waktu atau kata santai. Selaain itu, waaktu merupakan stopword sehhingga tidak akan menghasilkan dokumen apapun</p>\n",
    "\n",
    "<p>c. Dokumen B dan Dokumen C , karena dokumen B memiliki kata masyarakat dan mahasiswa sedangkan dokumen C memiliki kata sabar </p>\n",
    "\n",
    "<p>d. Dokumen B , karena tidak ada dokumen yang mempunyai kata waktu dan jenjang</p>\n",
    "\n",
    "<p>e. Dokumen C, karena tidak ada dokumen yang mempunyai (aktivitas AND pandemi) sehingga hanya memenuhi dokumen yang memiliki kata maksimal  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-prompt",
   "metadata": {},
   "source": [
    "#### 3. Apakah metode pemetaan dokumen dan teks dapat memberikan manfaat dalam proses perancangan sistem IR apabila dilihat dari perspektif keakuratan hasil yang akan dihasilkan? Jelaskan analisis singkat kamu minimal dalam 3 kalimat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-product",
   "metadata": {},
   "source": [
    "> Ya, menurut saya metode pemetaan dokumen dan teks dapat memberikan manfaat dalam proses perancangan sistem IR dan cukup akurat berdasarkan hasil yang dihasilkan. Walaupun keakuratan juga bergantung pada teknik memetakan antara kata-kata yang ada dengan kemunculanya pada satu atau beberapa dokumen namun cukup memberikan manfaat dalam perancangan sistem IR. Manfaat tersebut seperti mudah untuk dikembangkan dalam menghasilkan keakuratan yang cukup baik dan  merupakan struktur data paling populer yang digunakan dalam sistem IR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-initial",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
